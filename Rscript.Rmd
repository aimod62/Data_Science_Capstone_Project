---
title: "R script-Capstone Project"
author: "Astrid Melhado Dyer"
date: "6/16/2019"
output: html_document
---


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Data ann Rpackages Loading
library(mlbench)
library(caret)
library(dplyr)
library(psych)
library(knitr)
library(kableExtra)
library(corrplot)
library(rpart)
library(kernlab)
library(gbm)
library(randomForest)
library(Cubist)
data("BostonHousing2")
```


```{r echo= TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Data Partition
set.seed(13) # for reproducibility's purpose
train_index <- createDataPartition(BostonHousing2$cmedv, p=0.80, list = FALSE)
train_set <- BostonHousing2[train_index,]
test_set <- BostonHousing2[-train_index,]
```

```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
sapply(train_set, class)
```

```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
#The first 6 rows of our data set.
train_set <- train_set  %>% mutate(chas = as.numeric(as.character(chas)),
                                   town = as.numeric(as.factor(town))) %>%
  select(-medv) %>% select(cmedv, everything())
kable(head(train_set),format="latex", booktabs=TRUE) %>% 
  kable_styling(latex_options="scale_down")
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
dim(train_set)
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
tab <- describe(train_set[,2:18])

tab %>% mutate(SKEW = cell_spec(skew, "latex", color = ifelse(skew > 0.5 | skew < -0.5, "red", "black")),
  KURTOSIS = cell_spec(kurtosis, "latex", color = ifelse(kurtosis > 3 | kurtosis < -3, "blue", "black"))) %>%
  select(-skew, -kurtosis) %>%
  kable(format = "latex", escape = FALSE, booktabs=TRUE, linesep ="") %>%
  kable_styling(latex_options="scale_down") 
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA, fig.height= 8, fig.width= 8}
par(mfrow=c(3,6))
for(i in 2:18) {
  plot(density(train_set[,i]), main=names(train_set)[i])}
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA, fig.height= 8, fig.width= 8}
par(mfrow=c(3,6))
for(i in 2:18) {
boxplot(train_set[,i], main=names(train_set)[i])
}

```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA, fig.align='left'}
correlations <- cor(train_set[,2:18])
corrplot(correlations, method="circle")
```


```{r echo= TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
set.seed(13)
cutoff <- 0.75
correlations <- cor(train_set[,2:18])
highlyCorrelated <- findCorrelation(correlations, cutoff=cutoff)
for (value in highlyCorrelated) {
  print(names(train_set)[value])
}
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
train_set_1 <- train_set[,-highlyCorrelated]
dim(train_set_1)

```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
trainControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)#Standard approach
metric <- "RMSE"
```



```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}

#lm
set.seed(13)
fit.lm <- train(cmedv~., data=train_set_1, method="lm", metric=metric, preProc=c("center",
"scale", "BoxCox"), trControl=trainControl)
#glm
set.seed(13)
fit.glm <- train(cmedv~., data=train_set_1, method="glm", metric=metric, preProc=c("center",
"scale", "BoxCox"), trControl=trainControl)
#rpart
set.seed(13)
grid <- expand.grid(.cp=c(0, 0.05, 0.1))
fit.rpart<- train(cmedv~., data=train_set_1, method="rpart", metric=metric, tuneGrid = grid, preProc=c("center",
"scale", "BoxCox"), trControl=trainControl)
#svm
set.seed(13)
fit.svm <- train(cmedv~., data=train_set_1, method="svmRadial", metric=metric, preProc=c("center",
"scale", "BoxCox"), trControl=trainControl)
#KNN
set.seed(13)
fit.knn <- train(cmedv~., data=train_set_1, method="knn", metric=metric, preProc=c("center",
"scale", "BoxCox"), trControl=trainControl)
#GBM
set.seed(13)
fit.gbm <- train(cmedv~., data=train_set_1, method="gbm", metric=metric, preProc=c("center",
"scale", "BoxCox"), trControl=trainControl, verbose = FALSE)
#RF
set.seed(13)
fit.rf <- train(cmedv~., data=train_set_1, method="rf", metric=metric, preProc=c("center",
"scale", "BoxCox"),trControl=trainControl)
#Cubist
set.seed(13)
fit.cubist <- train(cmedv~., data=train_set_1, method="cubist", metric=metric,
preProc=c("center","scale", "BoxCox"), trControl=trainControl)
results <- resamples(list(LM=fit.lm, GLM=fit.glm, CART=fit.rpart, SVM=fit.svm, KNN = fit.knn,
                          GBM=fit.gbm, RF=fit.rf, CUBIST=fit.cubist))
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
summary(results)
```



```{r echo= TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Comparing the models: box and whisker plots
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)
```

.  

```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
# Comparing selected models: xyplot
xyplot(results, models=c("CUBIST", "RF"))

```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA }
# Manual Search
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
metric <- "RMSE"
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(train_set_1))))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000)) {
set.seed(13)
fit <- train(cmedv~., data = train_set_1, method="rf", metric=metric, tuneGrid=tunegrid,
trControl=trainControl, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Tune the Cubist model
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "RMSE"
set.seed(13)
tunegrid <- expand.grid(.committees=seq(10, 25, by=1), .neighbors=c(2, 3, 5, 8))
cubist_tuning <- train(cmedv~., data=train_set_1, method="cubist", metric=metric,
preProc=c("center", "scale", "BoxCox"), tuneGrid=tunegrid, trControl=trainControl)
print(cubist_tuning)
plot(cubist_tuning)

```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
set.seed(13)
x <- train_set_1[,2:14]
y <- train_set_1[,1]
preprocessed_data <- preProcess(x, method=c("center", "scale", "BoxCox"))
x_preprocessed <- predict(preprocessed_data, x)
finalModel <- cubist(x=x_preprocessed, y=y, committees=24)
summary(finalModel)
```


```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, comment=NA}
# transform the validation dataset
set.seed(13)
test_set_1 <- test_set %>% mutate(chas = as.numeric(as.character(chas)),
                                   town = as.numeric(as.factor(town))) %>%
  select(-medv, -rad, -town, -chas, -rm) %>% select(cmedv, everything())
new_df <- setdiff(train_set_1, test_set_1)
new_df
```


```{r echo=TRUE, eval= TRUE, message=FALSE, warning=FALSE, comment=NA}
test_set_x <- test_set_1[,2:14]
test_set_y <- test_set_1[,1]
test_set_x_preprocessed <- predict(preprocessed_data, test_set_x)
# use final model to make predictions on the validation dataset
predictions <- predict(finalModel, newdata=test_set_x_preprocessed, neighbors=2)
# calculate Metris
rmse <- RMSE(predictions, test_set_y)
r2 <- R2(predictions, test_set_y)
print(rmse)
```

```{r echo=TRUE, eval= TRUE, message=FALSE, warning=FALSE, comment=NA}
print(r2)
```
```
